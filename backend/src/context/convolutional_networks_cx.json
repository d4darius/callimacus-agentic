{
    "doc-start": {
        "heading": "Document Start",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": ""
    },
    "f7742979-b25f-4c22-b72a-e8c43e1901fe": {
        "heading": "Intro",
        "audio": " Music   All right, so.   today we will   We will focus on the second part.   of the   convolutional neural nets.   Lecture   Before we start, I know that in the first part of the time slot for the deep learning class.   You should have...   focused on the laboratory. ",
        "ocr": "",
        "additional_notes": "",
        "notes": "Certainly! Since only the audio transcription contains content, I will synthesize a cohesive introductory paragraph for your notes, ensuring clarity and logical flow, and anticipating the integration of further material as more sources become available.\n\n---"
    },
    "839afa3d-5d5c-4c17-8262-7724ffc9ccc4": {
        "heading": "Convolutional Neural Networks \u2013 Lecture Introduction",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": "It appears that you have not provided the actual content from the three sources (audio transcription, OCR text, and student notes). Please provide the text from each source, and I will synthesize them into a cohesive, well-structured paragraph as requested."
    },
    "2c90e9c3-9b8b-4122-9044-28187253667b": {
        "heading": "Lab notes",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": "when we should do the lab, sending instructions\n\nSo far we focused on technical aspects of conv neural networks"
    },
    "4cb4198d-5bc1-4465-ac4d-dd64be3a287e": {
        "heading": "What has been done",
        "audio": " which means that basically...   We have the ground tooth.   And we use algorithms.   to tune the parameters of our neural networks.   to address a particular task.   And the particular task is the find mainly  through the definition of the loss function.   So we have seen loss functions dedicated to regression problems and the loss functions dedicated to classification problems.   In particular   in the first part of the lecture on CNNs  before pushed on image classification.   which is interesting because it allows us to understand some of the technicalities related to...   a particular kind of filters that are called convolutional filters.   and how learning these filters is done.   In addition, we also discussed the connections that existed between...   the difficulty of training convolutional neural networks.   and   the behavior of stochastic approximation algorithms, stochastic optimization algorithms.   and   Now, the problem is that image classification can be found, we have...   seen, for example, in the first laboratory.   I   a data set that is very famous, it's called the MNIST data set, with very well defined.   images.   And, um,   We have discussed last time about other datasets that are very popular in the domain of   image classification that is   the C-FAR 10 or C-FAR 100 data site.   or the very large image net data set.   very broadly speaking, when we address image classification problems, we also talked about ",
        "ocr": "",
        "additional_notes": "",
        "notes": "In neural network training, we use algorithms to tune model parameters for specific tasks, which are defined primarily through the loss function. Loss functions differ based on the problem type, such as regression or classification. In the context of convolutional neural networks (CNNs), image classification tasks are particularly important, as they help illustrate technical aspects like convolutional filters and how these filters are learned. Training CNNs presents unique challenges, often linked to the behavior of stochastic optimization algorithms. Common datasets for image classification include MNIST, which contains well-defined images, as well as CIFAR-10, CIFAR-100, and the large-scale ImageNet dataset. These datasets are widely used to benchmark and study the performance of neural networks in image classification."
    },
    "8d81ac15-bfe2-40c0-9d5f-7cae341f5d49": {
        "heading": "Pre processing Steps",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": "They are necessary and they require clear labels to process"
    },
    "9d880262-5f59-42b8-80af-5fe9bc90f749": {
        "heading": "Computer vision",
        "audio": " in computer vision tasks.   The problem is a bit more difficult than in image classification.  First of all, the images are not necessarily...   well centered, they are not nice as they are in the data sets that we use for.   image classification.   there can be more than one object per image.   And   and the real world application require even more   techniques than simply classification.   to decide where are the objects.   and which objects are present in a scene.   a typical application could be, for example,  when you work in autonomous transportation systems.   I've set driving cars, for example.   where computer vision plays a crucial role.   But there are many other computer vision tasks related to health.   for example   uh   that required.   more advanced techniques than simple image classification.   Now, before we go through the slides, that... ",
        "ocr": "",
        "additional_notes": "",
        "notes": "In computer vision tasks, the challenges extend beyond those found in standard image classification. Images are often not well-centered or as clean as those in curated datasets, and a single image may contain multiple objects. Real-world applications require more advanced techniques than simple classification to both locate objects and identify which ones are present in a scene. For instance, autonomous transportation systems, such as self-driving cars, rely heavily on computer vision to interpret their surroundings. Similarly, applications in healthcare demand sophisticated methods that go beyond basic image classification to address complex visual scenarios."
    },
    "d150fb85-e71b-456a-9351-f7fd32f55d22": {
        "heading": "Going through the slides",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": "disclamer"
    },
    "c9a69f2e-fa8e-4f76-a7c5-dbcf3b59d200": {
        "heading": "NoSQL",
        "audio": " But this kind of opens up a trade of where else can I store it?  What other formats, what other systems are there that actually specialize in?   non-relational data storage, right? And that's exactly where this whole no-sequel moment  It actually came up.   So, Rosicone stands actually for not only sequel, it's a big misnomer because when you guys  probably were not a part of this buzz when it was going on.   This was, I think, around the time and big data and Hadoop was a big thing, right?  So, it was quite a long time ago.  And during this time, people really started off   discussing, you know, the fact that we have a lot more semi-structured data now,  we have a lot more data sitting in JSON files now that we don't want to store in a database.   that we don't want to query from a database.  And as I mentioned, they also needed greater scalability  than open source databases.   Notice two things here first commercial databases like Oracle have always scale so as I always say like if someone tells you the database relational databases do not scale that just   So, we have always been able to scale commercial databases, they cost money.   open source databases they are free but did not scale not anymore right now open source is caught up they are very very good   Now in fact databases have also caught up so a couple of years ago when I taught this lecture  I had pretty much this exact same slide. It was one year I think last year or the year before and somebody actually   said, well, I can actually query JSON from my database now entirely true, right? So databases  have also caught up. Now you can query JSON files from a database. You can query CSV files.  You can do direct lookup.   So, everything blurs because normally when a new functionality comes out, database engine  see that there is a market they can go after and they will immediately add a new functionality,  right.   It's changing, but at the time, when NoSQL was there,  they wanted this.  They wanted something that could scale  than a database, preference for free and open software.   Sir   a more dynamic model than a relational model, so they wanted the ability to not dictate the schema.   First, but something that can actually allow you to change schema more fluidly, more easily, right?  JSON is a very good example of that. So if you take this file stored in JSON, for example,   And I want to add one more field which could be for example I don't know like children or something like that right   I just basically go open up this file, add a field and I'm done.  If this is a database, it's a whole lot more complicated, right?  You have to add a particular column, link it to the other table which has the users.   lot more complicated. So this is what they wanted and and specialized query operations that are not  well supported by the relational model. I'll give you an example of that.   So, this is how no SQL was born, it was a Twitter hashtag for a meter and then it just took  off in a completely different direction right and people started using no SQL really as   argument against databases against SQL which is totally stupid because half of these systems  now support SQL or all of them now support SQL I should say right so it was really ",
        "ocr": "",
        "additional_notes": "",
        "notes": "The rise of **NoSQL databases** was driven by the need for scalable, flexible storage of **non-relational** and **semi-structured data**\u2014especially formats like `JSON`\u2014which traditional relational databases were not designed to handle efficiently.\n\n- This shift emerged during the **big data** and **Hadoop** era, as organizations faced growing volumes of semi-structured data and needed greater scalability than open source relational databases could provide at the time.\n- **Commercial databases** (e.g., `Oracle`) always offered scalability but were expensive, while open source solutions initially lagged behind\u2014though today, open source databases have largely caught up in scalability and features.\n- **NoSQL systems** introduced a more dynamic data model, enabling **flexible schema changes** without the rigid structure of relational models. For example, adding a new field to a `JSON` file is simple, whereas altering a relational schema is complex and time-consuming.\n- The original **NoSQL movement** was partly a reaction to these needs, but over time, the distinction between NoSQL and SQL databases has blurred:\n  - Many NoSQL systems now support `SQL` queries.\n  - Relational databases have added support for semi-structured formats like `JSON` and `CSV`.\n- This evolution demonstrates the **database industry's adaptability** to changing data management requirements and market opportunities, with new functionalities rapidly adopted across systems."
    },
    "181464c3-fd7b-4129-93dd-350f6c48f68f": {
        "heading": "NoSql Categories",
        "audio": "",
        "ocr": "",
        "additional_notes": "",
        "notes": "what are"
    },
    "226bc412-670a-449c-8853-b61a38f3ef2b": {
        "audio": " So, no sequence stands actually for not only sequence, it is a big misnomer because when  with this you guys probably would not a part of this bus when it was going on, this was   around the time and big data and Hadoop was a big thing, right? So it was quite a long  time ago. And during this time, people really started off...   discussing, you know, the fact that   We have a lot more semi structure data now.  We have a lot more data sitting in JSON files now  that we don't want to store in a database,  that we don't want to query from a database.   And as I mentioned, they also need a greater scalability than open source databases.   Notice two things here. First, commercial databases like Oracle have always scale.  So as I always say, like if someone tells you the relational databases do not scale, that's just wrong.   So, we have always been able to scale commercial databases, they cost money.   open source databases they are free but did not scale not anymore right now open source  is caught up they have very very good now in fact databases have also caught up so a couple  of years ago   when I taught this lecture, I had pretty much this exact same slide.  It was one year, I think last year or the year before.  And somebody actually said, well, I can actually query just on from my database now.  Entirely true.   So databases have also caught up now you can query JSON files from a database you can query CSV files you can do direct look up  So everything blurs because   Normally when a new functionality comes out database engine see that there is a market they can go after and they will immediately add a new functionality right so it's it's changing but at that   the time when no SQL was at, they wanted this, they wanted something that could scale  than a database, preference for free and open source software as I said.   a more dynamic model than a relational model, so they wanted the ability to not dictate the schema.   First, but something that can actually allow you to change schema more fluidly, more easily, right?  JSON is a very good example of that.  So if you take this file stored in JSON, for example,   And I want to add one more field which could be for example, I don't know like children or something like that right  I just basically go open up this file add a field and I'm done   If this is a database, it's a whole lot more complicated, right?  You have to add a particular column, link it to the other table which has the users,  a lot more complicated.   So this is what they wanted and specialized query operations that are not well supported  by the relational model.  I'll give you an example of that.  So this is how no SQL was born.  It was a Twitter hashtag for a meter.   And then it just took off in a completely different direction right and people started using  no sequel really as an argument against databases against SQL which is total   stupid because half of these systems now support SQL or all of them now support SQL I should  say right. So it was really not about SQL it was really about   These additional things that open source database  is didn't support at the time.  So you have four categories of these things,  and you will see some of these in your... ",
        "ocr": "[PDF PAGE CONTENT]: Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Consistency & DFS Lecture 8 1  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Resume Example \u2022 User table \u2022 Primary key: user_id \u2022 first_name and last_name as  columns  \u2022 One-to-many relationship \u2022 >1 job, contact information \u2022 Storing one-to-many \u2022 Normalized form \u2022 put positions, education, and  contact information in separate  tables \u2022 foreign key reference to the  users table \u2022 Retrieving data requires  complex joins \u2022 Can slow down perf 2  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Resume Example: JSON \u2022 Makes tree structure  of one-to-many  relationships explicit \u2022 Could potential  provide better perf \u2022 No need for joins 3  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems How about Many-to-one relationships? \u2022 region_id and industry_id as IDs or strings (\"Greater Seattle Area\"  and \"Philanthropy\u201c)? \u2022 Storing as ID \u2022 Avoid ambiguity & errors (data not copied) \u2022 Ease of updating (name is stored in only one place) \u2022 Localization support (multiple languages) \u2022 This is normalization! \u2022 But normalization leads to many-to-one \u2022 many people live in one region \u2022 How do we support many-to-one? \u2022 Databases can do joins across PK-FK \u2022 No support for join => app has to do a join \u2022 Even simple example illustrates tradeoffs 4  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL \u2022 Stands for Not-only SQL \u2022 originally intended simply as a catchy Twitter hashtag for a meetup on  open source, distributed, nonrelational databases in 2009 \u2022 Why were they designed \u2022 Need for greater scalability than open-source relational databases \u2022 Preference for free and open source software \u2022 Desire for a more dynamic and expressive data model than relational  model \u2022 Specialized query operations that are not well supported by the  relational model 5 ",
        "notes": "**NoSQL** stands for **Not-only SQL** and emerged as a response to the limitations of traditional relational databases, especially during the rise of big data and Hadoop. The main motivations behind NoSQL were:\n\n- **Scalability**: Open source relational databases historically struggled to scale, while commercial solutions like Oracle could scale but were costly. NoSQL systems aimed to provide scalable, free, and open source alternatives.\n- **Flexible Data Models**: There was a growing need to handle semi-structured data, such as `JSON` files, which allow for dynamic schemas. Unlike relational databases, where adding a new field requires altering the schema and potentially complex joins, NoSQL systems let users easily add fields to documents without rigid schema constraints.\n- **Performance**: Traditional normalized relational models require complex joins to represent one-to-many or many-to-one relationships, which can slow down performance. In contrast, storing data in formats like `JSON` makes hierarchical relationships explicit and eliminates the need for joins, potentially improving performance.\n- **Specialized Queries**: NoSQL databases were designed to support query operations not well handled by the relational model.\n\nOriginally, \"NoSQL\" was just a catchy Twitter hashtag for a meetup in 2009, but it quickly became associated with a movement toward open source, distributed, non-relational databases. Over time, relational databases have caught up, now supporting features like querying `JSON` and `CSV` files directly. The distinction between NoSQL and SQL systems has blurred, with many NoSQL systems now supporting SQL-like queries. Ultimately, NoSQL was never about rejecting SQL, but about addressing needs that relational databases did not meet at the time, such as scalability, flexibility, and specialized data handling.",
        "additional_notes": ""
    },
    "1e0b583d-4274-46c1-ba3c-b10289ae1b95": {
        "audio": " And that's exactly where this whole no-sequel moment actually came up.  So, no-sequel stands actually for not only sequel.   It's a big mistake because when you guys probably would not a part of this bus when it was going on   This was I think around the time and big data and Hadoop was a big thing, right?  So it was quite a long time ago and during this time people really started off   discussing, you know, the fact that we have a lot more semi-structured data now,  we have a lot more data sitting in JSON files now that we don't want to store in a database that we   don't want to query from a database and as I mentioned, they also need a greater scalability  than open source databases.   Notice two things here. First, commercial databases like Oracle have always killed.   So as I always say, if someone tells you  the relational databases do not scale, that's just wrong.  So we have always been able to scale commercial databases.  They cost money.   open source databases, they are free, but they did not scale.  Not anymore, right?  Now open source is caught up, they are very, very good.  Now, in fact, databases have also caught up.  So a couple of years ago,   and I taught this lecture. I had pretty much this exact same slide. It was one year, I think  last year or the year before. And somebody actually said, well I can actually query JSON from  my database now. Entirely true.   So databases have also caught up.  Now you can query JSON files from a database,  you can query CSV files, you can do direct look up.  So everything blurs because   Normally when a new functionality comes out database engine see that there is a market they can go after and they will immediately add a new functionality right so it's it's changing but at that   the time when NoSQL was there.   They wanted this, they wanted something that could scale  than a database, preference for free and open source software, as I said.   A more dynamic model than a relational model, so they wanted the ability to not dictate the schema.   First, but something that can actually allow you to change schema more fluidly, more easily, right?   JSON is a very good example of that. So if you take this file stored in JSON for example  and I want to add one more field which could be for example I don't know like children  or something.   like that right I just basically go open up this file add a field and I'm done   If this is a database, it's a whole lot more complicated.  You have to add a particular column, link it  to the other table which has the users,  a lot more complicated.  So this is what they wanted.  And.   And specialized query operations that are not well supported by the relational model.  I'll give you an example of that.  So this is how no SQL was born.  It was a Twitter hashtag for a meter.   And then it just took off in a completely different direction right and people started using  no sequel really as an argument against databases against SQL which is totally   stupid because half of these systems now support SQL or all of them now support SQL I should  say right. So it was really not about SQL it was really about   these additional things that open source databases  didn't support at the time.  So you have four categories of these things,  and you will see some of these in your... ",
        "ocr": "",
        "notes": "`NoSQL` stands for \"not only SQL\" and refers to a class of database systems that emerged to address the limitations of traditional relational databases, especially during the rise of big data and Hadoop.\n\n- Originated when semi-structured data (e.g., JSON files) became common and users wanted alternatives to storing and querying such data in relational databases.\n- Key motivations included:\n  - Need for greater **scalability** than what open source relational databases offered at the time.\n  - Preference for **free and open source** solutions.\n  - Desire for a **dynamic schema** model, allowing easy changes to data structure (e.g., adding fields to JSON without complex schema migrations).\n  - Support for **specialized query operations** not well handled by the relational model.\n- Commercial databases like Oracle have always been scalable, but were costly; open source databases lagged in scalability until recent years.\n- Modern databases have since caught up, now supporting querying of JSON, CSV, and other formats directly, blurring the lines between NoSQL and traditional databases.\n- The term `NoSQL` originated as a Twitter hashtag for a meetup and was later misinterpreted as being \"against SQL,\" even though many NoSQL systems now support SQL queries.\n\n> Example: Adding a new field to a JSON file is as simple as editing the file, while in a relational database, it requires altering the schema and managing table relationships.\n\nNoSQL databases were created to provide more flexible, scalable, and open solutions for handling modern data needs beyond the capabilities of early open source relational databases.",
        "additional_notes": ""
    },
    "5f5dcd9d-e3de-41a2-b28d-a534c95125d2": {
        "audio": " Google Cloud courses as well.  So the four types are key value stores.  So these are the most basic no SQL ones.  It's essentially a hash map.  So where key value stores you store   key and then you store a value associated with it key. So here are examples for example you can  store name a string and then you can store another string associated with it but with key value  stores, you can also store.   an ID and a file   So, for example, you are building a system, you know, that's tracking the temperature in  a particular place every day and what you do is that the data that you've got.   in your sensor, it comes in the form of a file, you push it to a key value store where  the ID is basically the date or ID is some random generated ID and the values actually the file.   So this is an example, right?  So you can use key well stores in many ways.  But typically key well stores are used for.   very small   keys and values, very tiny keys and values and generally they're used for create read update delete operation so basic you're creating a key reading updating the key value and deleting it that's it they don't   report any more complex operations, there is no SQL on top of a key value store, although  people have implemented that and there are solutions that do that.   It scales very well, so if you are doing lookups, you can do massive number of lookups on  and key value stores.   millions of lookups per second as I said it's not meant for complex queries and the interesting  part here when it comes to atomic sun this is where I started this totally guys right so we know   when it comes to updates, how database is handled, here is the part about updates for key value  stores, they are atomic for single keys only, so you can read and write keys.   Automically, so when you're writing a key one key value someone else needs the key you are guaranteed that they would actually  You know they'll get serialized behind you  But there is no transactions across keys   Okay.   The value is opaque, there's no indexing and querying and all that so here is example key value stores you have dynamo db redis webcached.  These are all very very very popular solutions.   And they are typically used, you know, for many, many use cases, a very good use case  here is for example, for caching session information.  So whenever you visit a website.   There are cookies that get stored on your browser.  There is also the session information.  What browser are you using?  Where location are you contacting from?  What is your previous activity?   All of this information is basically key and value.  And all of this information can be retrieved on the server  site.  And this is how when you go to search for something on Google,  and then you go to another.   place, you see ads relevant to your search, right? So all of this information is typically  stored on a key value store somewhere in one of the cloud platforms. ",
        "ocr": "[PDF PAGE CONTENT]: Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph stores \u2022 Store key-value pairs \u2022 Essentially a hashmap \u2022 Ideal for basic Create-Read-Update-Delete  (CRUD) ops \u2022 Scales well \u2022 Not meant for complex queries \u2022 Atomic for single keys only! \u2022 No multi-ops transactions or ACID \u2022 Value is opaque \u2022 No indexing and querying over values \u2022 Ex: DynamoDB, Redis, Memcached \u2022 Use case : Storing and retrieving user session  information 6  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph stores \u2022 Extend KV model by making values visible and  queryable \u2022 Stores documents (JSON, XML usually) \u2022 Flexible schema, documents can be indexed \u2022 Atomic operations on single document! \u2022 Denormalize data  \u2022 Add redundancy to make docs self contained \u2022 Avoid many-to-one problem \u2022 Ex: MongoDB, CouchDB \u2022 Use case: Event logging for application, data for  mobile/web apps  7 ",
        "notes": "`Key-value stores` are the most basic type of NoSQL databases, functioning essentially as hashmaps that store pairs of keys and associated values.\n\n$$\n\\text{Key} \\rightarrow \\text{Value}\n$$\n\n- Store data as simple key-value pairs.\n- Ideal for basic **Create-Read-Update-Delete (CRUD)** operations.\n- Values can be any data type (e.g., string, file, binary blob).\n- Typically used for small, simple data items.\n- **Scales extremely well** for massive numbers of lookups (millions per second).\n- Not designed for complex queries; no SQL layer by default.\n- **Atomicity** is guaranteed for single-key operations only.\n- No support for multi-key transactions or full ACID properties.\n- The value is **opaque**: no indexing or querying over the value itself.\n- Common implementations: DynamoDB, Redis, Memcached.\n\n> Example: Storing and retrieving user session information (e.g., browser type, location, previous activity) for web applications, or caching sensor data files using a unique ID as the key.\n\nKey-value stores are crucial for high-performance, simple data access patterns but are not suitable for complex querying or transactional workloads.",
        "additional_notes": ""
    },
    "d13f16ec-92c7-4f0a-b8c7-ecfc97b58dc4": {
        "audio": " was going on. This was I think around the time and big data and Hadoop was a big thing,  right. So it was quite a long time ago.   And during this time, people really started off discussing the fact that   We have a lot more semi-structured data now.  We have a lot more data sitting in JSON files now  that we don't want to store in a database,  that we don't want to query from a database.  And as I mentioned,   but they also need a greater scalability than open source databases.   Notice two things here, first, commercial databases,  like Oracle, have always scale.  So as I always say, if someone tells you  the relational databases do not scale, that's just wrong.   So, we have always been able to scale commercial databases, they cost money.   open source databases, they are free, but they did not scale.  Not anymore, right?  Now open source is caught up, they are very, very good.  Now, in fact, databases are also caught up.  So a couple of years ago,   when I taught this lecture, I had pretty much this exact same slide.  It was one year, I think last year or the year before.  And somebody actually said, well, I can actually query just on from my database now.  Entirely true.   right. So databases have also caught up. Now you can query JSON files from a database. You can  query CSV files. You can do direct look up. So everything blurs because   Normally when a new functionality comes out database engine see that there is a market they can go after and they will immediately add a new functionality right so it's it's changing but at that   the time when no SQL was at, they wanted this, they wanted something that could scale  than a database, preference for free and open source software as I said.   a more dynamic model than a relational model so did they wanted the ability to not dictate the schema   First, but something that can actually allow you to change schema more fluidly, more easily, right?   JSON is a very good example of that.  So if you take this file stored in JSON, for example,  and I want to add one more field,  which could be, for example, I don't know, like,   children or something like that right I just basically go open up this file add a field  done, I am done.   If this is a database, it's a whole lot more complicated, right?  You have to add a particular column, link it to the other table which has the users,  a lot more complicated.   So this is what they wanted and specialized query operations that are not well supported  by the relational model.  I'll give you an example of that.  So this is how no SQL was born.  It was a Twitter hashtag for a meter.   And then it just took off in a completely different direction and people started using no  sequel really as an argument against databases against SQL which is total   will stupid because half of these systems now support SQL or all of them now support  SQL I should say right. So it was really not about SQL it was really about   these additional things that open source databases  didn't support at the time.  So you have four categories of these things,  and you will see some of these in your... ",
        "ocr": "",
        "notes": "`NoSQL` databases emerged during the rise of big data and Hadoop, addressing the need to handle increasing amounts of semi-structured data, such as JSON files, that users did not want to store or query using traditional relational databases.\n\n- **Key motivations for NoSQL:**\n  - Need for greater scalability than open source relational databases could provide at the time.\n  - Preference for free and open source solutions over costly commercial databases like Oracle.\n  - Desire for a more dynamic, flexible schema model (e.g., easily adding fields to JSON files without complex schema migrations).\n  - Requirement for specialized query operations not well supported by the relational model.\n\n- **Evolution of database capabilities:**\n  - Commercial relational databases have always been able to scale, but at a financial cost.\n  - Open source databases initially lacked scalability, but have since caught up and now offer robust performance.\n  - Modern databases now support querying semi-structured data formats (e.g., JSON, CSV) directly, blurring the lines between NoSQL and traditional databases.\n  - Database engines rapidly adopt new functionalities in response to market demand.\n\n- **Misconceptions:**\n  - The term `NoSQL` originated as a Twitter hashtag for a meetup, not as an explicit rejection of SQL.\n  - Many NoSQL systems now support SQL, so the distinction is no longer about the query language but about additional features and flexibility.\n\n> Example: Adding a new field to a JSON file in a NoSQL system is as simple as editing the file, whereas in a relational database, it requires altering the schema and potentially updating related tables.\n\nNoSQL databases were developed to address limitations in scalability, flexibility, and data modeling that existed in early open source relational databases, but modern systems have largely closed these gaps.",
        "additional_notes": ""
    },
    "e655aac5-65c1-4549-9f7d-953594ad7044": {
        "audio": " Okay, so the second kind is what's called a document store, where you extend key value  model by making the values visible and queryable effectively, so you're storing documents here,  right?   JSON, XML and so on, which gives you a flexible schema,  we just discussed this.  You have atomic operations on one document.  You can update a document automatically.   You can delete the document and so on, you cannot get an atomicity within a document, there is no concept like that.   So you can, it's like effectively a locking a whole document and then you update it.  So you have to denormalize the data, the idea of this.  We just discussed this in the previous case.   So, this is like the avoiding the many to one problem we discussed here.   Um,   So you have to, what I mentioned here,  with the denormalization is you have the IDs here  and then you have the mapping of IDs to strings,  you have to denormalize it.   Okay.   An example of these are MongoDB and CoachDB.   And once again, a very good use case is event logging,  as I just mentioned, with sensor data  or data for mobile and web apps,  these are very, very common.  Third type is a white column store.  This is built off of... ",
        "ocr": "[PDF PAGE CONTENT]: Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph stores \u2022 Extend KV model by making values visible and  queryable \u2022 Stores documents (JSON, XML usually) \u2022 Flexible schema, documents can be indexed \u2022 Atomic operations on single document! \u2022 Denormalize data  \u2022 Add redundancy to make docs self contained \u2022 Avoid many-to-one problem \u2022 Ex: MongoDB, CouchDB \u2022 Use case: Event logging for application, data for  mobile/web apps  7 ",
        "notes": "`Document store` databases extend the key-value model by making values visible and queryable, allowing storage and retrieval of entire documents such as JSON or XML.\n\n- **Flexible schema:** Supports dynamic and varied document structures.\n- **Atomic operations:** Guarantees atomicity only at the single-document level.\n- **Data denormalization:** Requires embedding related data within documents to avoid many-to-one relationships.\n- **Redundancy:** Adds redundancy to make documents self-contained.\n- **Indexing:** Documents can be indexed for efficient querying.\n- **No intra-document atomicity:** Operations lock and update the whole document, not parts of it.\n\n> Examples: MongoDB, CouchDB  \n> Use cases: Event logging, sensor data collection, and storing data for mobile or web applications.\n\nDocument stores are widely used for applications requiring flexible schemas and efficient handling of semi-structured data.",
        "additional_notes": ""
    },
    "9baa135f-7914-4a16-af99-0239944c2d28": {
        "audio": " these additional things that open source databases  didn't support at the time.  So you have four categories of these things,  and you will see some of these in your...   Google Cloud courses as well.  So the four types are key value stores.  So these are the most basic no-sequel ones.  It's essentially a hash map.  So where key value stores you store   key and then you store a value associated with it key. So here are examples for example you can  store name a string and then you can store another string associated with it but with key value  stores, you can also store.   an ID and a file   So, for example, you are building a system that is tracking the temperature in a particular  place every day.   And what you do is that the data that you gather in your sensor, it comes in the form of a file,  you push it to a key value store where the ID is basically the date or ID is some random generator ID.   and the values actually the file. So, this is an example, right? So, you can use QL  stores in many ways. But typically, QL stores are used for   very small   keys and values very tiny keys and values and generally they're used for create read update delete operation so basic you're creating a key reading updating the key value and deleting it that's it they don't   support any more complex operations, there is no SQL on top of a key value store, although  people have implemented that.   And there are solutions that do that.  It scales very well.  So if you are doing lookups, you can do massive number  of lookups on key value stores.   millions of lookups per second and as I said it is not meant for complex queries and  the interesting part here when it comes to atom X and this is where I started this  I told you guys, right?  So, we...   know when it comes to updates, how database is handled, here is a part of updates for key  value stores.  They are atomic for single keys only, so you can read and write keys atomically.   writing a key, one key value, someone else reads the key, you are guaranteed that they  would actually, you know, they will get serialized behind you.   But there is no transactions across keys, okay.   The value is opaque, there's no indexing and querying and all that.  So here is example key value stores.  You have DynamoDB, readers, webcached.   These are all very, very, very popular solutions, and they are typically used, you know, for  many, many use cases, a very good use case here is, for example, for caching session information.   So whenever you visit a website, there are cookies that get stored on your browser.  There is also the session information. What browser are you using?  Where location are you contacting from?   what is your previous activity. All of this information is basically key and value, okay.   And all of this information can be retrieved on the server side.  And this is how when you go to search for something on Google,  and then you go to another place, you see ads relevant to your search, right?   So all of this information is typically stored on a key value store somewhere in one of the cloud platforms. ",
        "ocr": "",
        "notes": "`Key value stores` are a fundamental category of NoSQL databases designed to store and retrieve data as simple key-value pairs.\n\n- **Structure:** Data is stored as a key (e.g., string, ID, date) and an associated value (e.g., string, file).\n- **Operations:** Support only basic operations\u2014create, read, update, and delete (CRUD).\n- **Complexity:** Do not support complex queries or SQL-like operations natively.\n- **Atomicity:** Updates are atomic for single keys only; no transactions across multiple keys.\n- **Scalability:** Highly scalable, capable of handling millions of lookups per second.\n- **Data Handling:** Values are opaque (not indexed or queryable beyond the key).\n- **Typical Use Cases:** \n  - Caching session information (e.g., user sessions, cookies, browser data)\n  - Storing sensor data files with IDs as keys\n  - Any scenario requiring fast, simple lookups\n\n> Example: Storing daily temperature sensor files where the key is the date or a generated ID, and the value is the file itself.\n>\n> Example: Session information for web applications, such as user activity, browser type, and location, stored as key-value pairs for fast retrieval.\n\n**Popular solutions:** DynamoDB, Redis, Memcached.\n\nKey value stores are essential for applications requiring high-speed, simple data access without complex querying needs.",
        "additional_notes": ""
    },
    "c0e9cfc2-a24f-4528-8925-34f8231df15d": {
        "audio": " OK, so the second kind is what's called a document store,  where you extend key value model by making  the values visible and queryable effectively.  So you're storing documents here, right?  So you have.   JSON, XML and so on, which gives you a flexible schema,  which I just discussed this.  You have atomic operations on one document.  You can update a document automatically.   you can delete the document and so on you cannot get  atomicity within a document. There is no concept like that.   So you can, it's like effectively a locking a whole document and then you update it.  So you have to denormalize the data, the idea of this, we just discussed this in the previous case.   So this is like the avoiding the many to one problem we discussed here.   Um.   So you have to, what I mentioned here,  with the denormalization is you have the IDs here,  and then you have the mapping of IDs to strings,  you have to denormalize it.   Okay.   An example of these are MongoDB and CoachDB. ",
        "ocr": "[PDF PAGE CONTENT]: Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph stores \u2022 Extend KV model by making values visible and  queryable \u2022 Stores documents (JSON, XML usually) \u2022 Flexible schema, documents can be indexed \u2022 Atomic operations on single document! \u2022 Denormalize data  \u2022 Add redundancy to make docs self contained \u2022 Avoid many-to-one problem \u2022 Ex: MongoDB, CouchDB \u2022 Use case: Event logging for application, data for  mobile/web apps  7 ",
        "notes": "`Document store` databases extend the key-value model by making values visible and queryable, allowing storage and retrieval of entire documents.\n\n- Store documents in formats like **JSON** or **XML**\n- Support a **flexible schema**; documents can be indexed\n- Allow **atomic operations** on a single document (update, delete, etc.)\n- Require **denormalization** of data to make documents self-contained\n- Add redundancy to avoid the **many-to-one problem**\n- No atomicity across multiple documents; operations are atomic only within a single document\n\n> Examples: MongoDB, CouchDB  \n> Use cases: Event logging for applications, storing data for mobile/web apps\n\nDocument stores are important for applications needing flexible schemas and efficient document-level operations.",
        "additional_notes": ""
    },
    "9e4f7f71-c637-47ae-b5c8-3c635f326099": {
        "audio": " And once again, a very good use case is event logging.  As I just mentioned, with sensor data,  or data for mobile and web apps,  these are very, very common.  Third type is a white column store.  This is built off of...   Google Bigtable. So you will hear about this in one of your lectures from GCSB. Bigtable  really builds off of the relational model. So you have a table. So when we define a relation   in a database, you actually have a fixed number of columns and a fixed number of rows.  And each row basically, each column has a type.   And there are a certain number of columns per row and when you enter a record you have to fill in every single column that you have on that record   What if your records are actually a variable size?  What if one record has many more columns and another one doesn't?   What if your cell itself is a complex type?  What if your cell you want to store not just an integer or a string  but you actually want to store something like a structure like a JSON.   document, like a hierarchy.  So in all these cases, the relational model is still not suitable for this.  So Bigtable extends the model and it gives you this ability to have   variable size rows, cells that are more complex, right, more complex types and things like  that. And it's very good for dealing with sparse data. So if you want to have a table  This is where...   You know, imagine you are creating, imagine you, this is your data, right?  So you have one record which is huge, right?   1 million columns and then you have another record which, where you are storing just   10 columns, another record which is storing 100 columns.   In a relational database, you would have to have a table containing 1 million columns.  Everything is flattened out.  And for this record, these columns would be empty, right?  This record, this column, would be empty.  But you still...   need to have the schema. You still need to fill in those with zeros or null or whatever  and store it. Bigtable naturally supports this kind of formats. So this is what's called  spars, cos data here.   here is not there, here is not there.  So it's built for past storage like this.  It can work very well.  And it can read and write automatically at a role level.   So you can one row, you can actually read and write automatically.  Notice the distinction.   of each and every one of these with respect to how they offer atomic updates, right?   With databases you had the notion of transactions, data lakes now you have the notion of transactions.   With these, you have the notion of atomic axis, right?   So it's very different, right?  So you don't get the same guarantees  that you get from databases or data lakes. ",
        "ocr": "[PDF PAGE CONTENT]: Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph  stores \u2022 Built off of Google BigTable \u2022 Builds off relational model to accommodate  rows with different number of columns \u2022 Good for dealing with sparse data \u2022 Rows need not store empty columns \u2022 Reads/writes atomic at row level! \u2022 Ex: Cassandra, Hbase \u2022 Niche use cases 8  \n Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems Raja Appuswamy (Eurecom) Cloud Computing and Distributed Systems NoSQL Categories \u2022 4 types \u2022 Key-value stores, Document stores, wide column stores, Graph stores \u2022 Excellent for graph-structured data \u2022 Entities as nodes, relationships as edges \u2022 Ex: Routing, spatial, map, social media data \u2022 Can provide ACID updates to graph data \u2022 Ex: Neo4j, Neptune \u2022 Niche use cases 9 ",
        "notes": "`wide column store` is a NoSQL database model designed to efficiently handle variable-sized, sparse, and complex data structures, extending the traditional relational model.\n\n- Built on concepts from Google Bigtable.\n- Supports rows with a different number of columns, unlike relational databases which require a fixed schema.\n- Each cell can store complex types, such as JSON documents or hierarchical structures.\n- Optimized for sparse data; rows do not need to store empty columns.\n- Enables atomic read/write operations at the row level, but does not provide full transactional guarantees like traditional databases.\n- Well-suited for event logging, sensor data, and mobile/web app data.\n- Common implementations include Cassandra and HBase.\n- Typically used for niche scenarios where data sparsity and flexibility are required.\n\n> Example: In a `wide column store`, one record might have 1 million columns while another has only 10, without wasting storage on empty columns.\n\nWide column stores are crucial for applications requiring flexible schemas and efficient handling of large, sparse datasets.",
        "additional_notes": ""
    }
}